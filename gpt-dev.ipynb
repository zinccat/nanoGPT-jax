{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nanoGPT-jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 1115394\n"
     ]
    }
   ],
   "source": [
    "print(\"length of text:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(\"text:\", text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda x: [stoi[ch] for ch in x]\n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "\n",
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115394,) int32\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "data = np.array(encode(text), dtype=np.int32) # no default int64, use numpy for underlying data\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train val split\n",
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [18] target is 47\n",
      "when input is [18 47] target is 56\n",
      "when input is [18 47 56] target is 57\n",
      "when input is [18 47 56 57] target is 58\n",
      "when input is [18 47 56 57 58] target is 1\n",
      "when input is [18 47 56 57 58  1] target is 15\n",
      "when input is [18 47 56 57 58  1 15] target is 47\n",
      "when input is [18 47 56 57 58  1 15 47] target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context, target = x[:t+1], y[t]\n",
    "    print(f\"when input is {context} target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "(4, 8)\n",
      "[[52  1 39 56 51 57  6  0]\n",
      " [48 59 42 45 43 42  1 40]\n",
      " [49 43  1 58 47 50 50  1]\n",
      " [58 53 51 40 57  8  0  0]]\n",
      "targets:\n",
      "(4, 8)\n",
      "[[ 1 39 56 51 57  6  0 13]\n",
      " [59 42 45 43 42  1 40 63]\n",
      " [43  1 58 47 50 50  1 63]\n",
      " [53 51 40 57  8  0  0 15]]\n",
      "-----\n",
      "when input is [52] target is 1\n",
      "when input is [52  1] target is 39\n",
      "when input is [52  1 39] target is 56\n",
      "when input is [52  1 39 56] target is 51\n",
      "when input is [52  1 39 56 51] target is 57\n",
      "when input is [52  1 39 56 51 57] target is 6\n",
      "when input is [52  1 39 56 51 57  6] target is 0\n",
      "when input is [52  1 39 56 51 57  6  0] target is 13\n",
      "when input is [48] target is 59\n",
      "when input is [48 59] target is 42\n",
      "when input is [48 59 42] target is 45\n",
      "when input is [48 59 42 45] target is 43\n",
      "when input is [48 59 42 45 43] target is 42\n",
      "when input is [48 59 42 45 43 42] target is 1\n",
      "when input is [48 59 42 45 43 42  1] target is 40\n",
      "when input is [48 59 42 45 43 42  1 40] target is 63\n",
      "when input is [49] target is 43\n",
      "when input is [49 43] target is 1\n",
      "when input is [49 43  1] target is 58\n",
      "when input is [49 43  1 58] target is 47\n",
      "when input is [49 43  1 58 47] target is 50\n",
      "when input is [49 43  1 58 47 50] target is 50\n",
      "when input is [49 43  1 58 47 50 50] target is 1\n",
      "when input is [49 43  1 58 47 50 50  1] target is 63\n",
      "when input is [58] target is 53\n",
      "when input is [58 53] target is 51\n",
      "when input is [58 53 51] target is 40\n",
      "when input is [58 53 51 40] target is 57\n",
      "when input is [58 53 51 40 57] target is 8\n",
      "when input is [58 53 51 40 57  8] target is 0\n",
      "when input is [58 53 51 40 57  8  0] target is 0\n",
      "when input is [58 53 51 40 57  8  0  0] target is 15\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "key, subkey = jax.random.split(rng)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = np.random.randint(0, data.shape[0] - block_size, batch_size)\n",
    "    x = jnp.stack([data[i:i+block_size] for i in ix])\n",
    "    y = jnp.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"-----\")\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context, target = xb[b, :t+1], yb[b, t]\n",
    "        print(f\"when input is {context} target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 65)\n",
      "4.1879272\n",
      "\n",
      "yFlSnelZW$eod&mx&hF!OYNmyFf;Z;e-peU?JgFLPeuwoMmZaYH?wgihUj?ltK\n",
      "\n",
      "KhqBwWPBEEuiYZnQM,WtQA-fjI3z ZH3.Wq:\n",
      "\n",
      "yFlSnelZW$eod&mx&hF!OYNmyFf;Z;e-peU?JgFLPeuwoMmZaYH?wgihUj?ltK\n",
      "\n",
      "KhqBwWPBEEuiYZnQM,WtQA-fjI3z ZH3.Wq:\n"
     ]
    }
   ],
   "source": [
    "import flax.linen as nn\n",
    "import optax\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    vocab_size: int\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, idx: jnp.ndarray, targets: jnp.ndarray = None):\n",
    "        logits = nn.Embed(num_embeddings=self.vocab_size, features=self.vocab_size)(idx) # (bs, block_size, \n",
    "        if targets is None:\n",
    "            return logits, 0\n",
    "        logits_reshaped = rearrange(logits, 'b t c -> (b t) c')\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(logits_reshaped, targets.flatten())\n",
    "        return logits, jnp.mean(loss)\n",
    "\n",
    "    def generate(self, params, subkey, idx, max_new_tokens: int = 100):\n",
    "        # pad idx to max_new_tokens\n",
    "        idx = jnp.pad(idx, ((0,0), (0, max_new_tokens)), mode='constant', constant_values=0)\n",
    "\n",
    "        @jax.jit\n",
    "        def step_fn(i: int, idx: jnp.ndarray, key: jnp.ndarray):\n",
    "            logits, loss = self.apply(params, idx)\n",
    "            logits = logits[:, i, :] # we are not using the logits from the rest of the sequence\n",
    "            token = jax.random.categorical(key, logits)\n",
    "            new_idx = idx.at[:, i+1].set(token)\n",
    "            return new_idx\n",
    "        for i in range(max_new_tokens):\n",
    "            subkey, key = jax.random.split(subkey)\n",
    "            idx = step_fn(i, idx, key)\n",
    "        return jnp.array(idx)\n",
    "\n",
    "m = BigramLanguageModel(vocab_size=vocab_size)\n",
    "params = m.init(subkey, xb, yb)\n",
    "out, loss = m.apply(params, xb, yb)\n",
    "print(out.shape)\n",
    "print(loss)\n",
    "\n",
    "idx = jnp.zeros((1, 1), dtype=jnp.int32)\n",
    "print(decode(np.array(m.generate(params, subkey, idx, max_new_tokens=100)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss: 4.1635 Elapsed time: 0.15869743993971497\n",
      "Step 2000, Loss: 3.3745 Elapsed time: 1.1456453750142828\n",
      "Step 4000, Loss: 2.8744 Elapsed time: 2.1243199419695884\n",
      "Step 6000, Loss: 2.4439 Elapsed time: 3.0988453349564224\n",
      "Step 8000, Loss: 2.5445 Elapsed time: 4.09691127599217\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "optimizer = optax.adamw(1e-3)\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "@jax.jit\n",
    "def train_step(params, opt_state, xb, yb):\n",
    "    def loss_fn(params):\n",
    "        logits, loss = m.apply(params, xb, yb)\n",
    "        return loss\n",
    "    \n",
    "    loss, grad = jax.value_and_grad(loss_fn)(params)\n",
    "    updates, opt_state = optimizer.update(grad, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    return params, opt_state, loss\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "for step in range(10000):\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    params, opt_state, loss = train_step(params, opt_state, xb, yb)\n",
    "    \n",
    "    if step % 2000 == 0:  # Print loss every 100 steps\n",
    "        jax.block_until_ready(loss)\n",
    "        print(f\"Step {step}, Loss: {loss:.4f}\", \"Elapsed time:\", timer() - start_time)\n",
    "        idx = jnp.zeros((1, 1), dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VjHot lle\n",
      "Whys.\n",
      "HARDUno r lPrng;'sy.\n",
      "TI a s vit nclmpe d ak onerfayo s akin th,\n",
      "RGandoug f at aghors\n",
      "Afanend me, shav-IZG arsg ICUCUCAloudsthe gu\n",
      "Ane m ahe, toat pt ohour mn\n",
      "THEDe boo geore.\n",
      "Y:\n",
      "He th I vike inth'ethit.\n",
      "Pue mihen emar thin ang ofond ut t sp n s hakQLYZig, Thithou!yindss s brod BUME-\n",
      "Tongpaw,\n",
      "imat thex, Hxfayos he s s m:\n",
      "\n",
      "Ange arine'me hiknOPE:\n",
      "BWhmpr conot: is TUCost GHERK:\n",
      "AMalamutstharthr;\n",
      "OL:\n",
      "DIZGzMjourngint!\n",
      "IAnf tinhou, Therinceswhingend ofenedentoure.\n",
      "Toumanthee p,\n",
      "AUNCINCE\n"
     ]
    }
   ],
   "source": [
    "idx = jnp.zeros((1, 1), dtype=jnp.int32)\n",
    "subkey, key = jax.random.split(subkey)\n",
    "print(decode(np.array(m.generate(params, key, idx, max_new_tokens=500)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
